{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "zip = ZipFile('Resources/archive.zip')\n",
    "zip.extractall('Resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all the columns (to see which to drop)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Mutual Fund informaiton csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in CSV data \n",
    "#MutualFunds\n",
    "mutualFunds= pd.read_csv(\n",
    "    Path(\"Resources/MutualFunds.csv\")\n",
    ",index_col=\"fund_symbol\")\n",
    "mutualFunds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with only 1 value to drop\n",
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates to date\n",
    "mutualFunds[\"inception_date\"] = pd.to_datetime(mutualFunds[\"inception_date\"])\n",
    "mutualFunds[\"management_start_date\"] = pd.to_datetime(mutualFunds[\"management_start_date\"])\n",
    "mutualFunds[\"returns_as_of_date\"] = pd.to_datetime(mutualFunds[\"returns_as_of_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds_counts= mutualFunds.loc[: ,mutualFunds.dtypes==\"object\"].nunique()\n",
    "mutualFunds_counts_one= mutualFunds_counts[mutualFunds_counts == 1].index.to_list()\n",
    "print(mutualFunds_counts_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with only 1 unique value\n",
    "mutualFunds.drop(columns=mutualFunds_counts_one,inplace=True)\n",
    "mutualFunds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_We noticed that there are many `NaN` values throughout the data set. We will now explore which columns/rows have NaN and will remove an appropriate amount of columns/rows._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we drop rows that have an `NaN`, then all data is removed. Instead, let's look at the columns that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at each column and the count of NaN in each column\n",
    "list = []\n",
    "for index, row in pd.DataFrame(mutualFunds.isna().sum()).iterrows():\n",
    "    list.append((index,row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Missing Values\n",
    "# Fill missing values in numerical columns with mean or median\n",
    "numerical_cols = mutualFunds.select_dtypes(include=['number']).columns\n",
    "mutualFunds[numerical_cols] = mutualFunds[numerical_cols].fillna(mutualFunds[numerical_cols].mean())\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "categorical_cols = mutualFunds.select_dtypes(include=['object']).columns\n",
    "mutualFunds[categorical_cols] = mutualFunds[categorical_cols].fillna(mutualFunds[categorical_cols].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Variables\n",
    "# One-hot encode categorical variables\n",
    "mutualFunds_encoded = pd.get_dummies(mutualFunds, columns=categorical_cols)\n",
    "\n",
    "# Scaling Numerical Features\n",
    "# Separate numerical columns for scaling\n",
    "numerical_cols = mutualFunds_encoded.select_dtypes(include=['number']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to find the number of columns that have above a certain percentage of `NaN` and then remove those columns. We have chosen 60% so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6*len(mutualFunds)\n",
    "drop_columns = []\n",
    "for i in range(len(list)):\n",
    "    if list[i][1][0] >= threshold:\n",
    "        drop_columns.append(list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(drop_columns))\n",
    "drop_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.drop(columns=drop_columns, inplace = True)\n",
    "mutualFunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with only 1 value to drop\n",
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "mutualFunds.drop(columns=[\"fund_short_name\", \"fund_long_name\",\"management_name\", \"management_bio\", \"investment_strategy\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove quarterly data\n",
    "mutualFunds.drop(columns=[\"fund_return_2021_q1\",\n",
    "\"fund_return_2020_q4\",\"fund_return_2020_q3\",\"fund_return_2020_q2\",\"fund_return_2020_q1\",\n",
    "\"fund_return_2019_q4\",\"fund_return_2019_q3\",\"fund_return_2019_q2\",\"fund_return_2019_q1\",\n",
    "\"fund_return_2018_q4\",\"fund_return_2018_q3\",\"fund_return_2018_q2\",\"fund_return_2018_q1\",\n",
    "\"fund_return_2017_q4\",\"fund_return_2017_q3\",\"fund_return_2017_q2\",\"fund_return_2017_q1\",\n",
    "\"fund_return_2016_q4\",\"fund_return_2016_q3\",\"fund_return_2016_q2\",\"fund_return_2016_q1\",\n",
    "\"fund_return_2015_q4\",\"fund_return_2015_q3\",\"fund_return_2015_q2\",\"fund_return_2015_q1\",\n",
    "\"fund_return_2014_q4\",\"fund_return_2014_q3\",\"fund_return_2014_q2\",\"fund_return_2014_q1\",\n",
    "\"fund_return_2013_q4\",\"fund_return_2013_q3\",\"fund_return_2013_q2\",\"fund_return_2013_q1\",\n",
    "\"fund_return_2012_q4\",\"fund_return_2012_q3\",\"fund_return_2012_q2\",\"fund_return_2012_q1\",\n",
    "\"fund_return_2011_q4\",\"fund_return_2011_q3\",\"fund_return_2011_q2\",\"fund_return_2011_q1\",\n",
    "\"fund_return_2010_q4\",\"fund_return_2010_q3\",\"fund_return_2010_q2\",\"fund_return_2010_q1\",\n",
    "\"fund_return_2009_q4\",\"fund_return_2009_q3\",\"fund_return_2009_q2\",\"fund_return_2009_q1\",\n",
    "\"fund_return_2008_q3\",\"fund_return_2008_q2\",\"fund_return_2008_q1\",\n",
    "\"fund_alpha_3years\",\"fund_beta_3years\",\"fund_mean_annual_return_3years\",\"fund_r_squared_3years\",\"fund_stdev_3years\",\"fund_sharpe_ratio_3years\",\"fund_treynor_ratio_3years\",\n",
    "\"fund_alpha_5years\",\"fund_beta_5years\",\"fund_mean_annual_return_5years\",\"fund_r_squared_5years\",\"fund_stdev_5years\",\"fund_sharpe_ratio_5years\",\"fund_treynor_ratio_5years\",\n",
    "\"fund_alpha_10years\",\"fund_beta_10years\",\"fund_mean_annual_return_10years\",\"fund_r_squared_10years\",\"fund_stdev_10years\",\"fund_sharpe_ratio_10years\",\"fund_treynor_ratio_10years\",\n",
    "\"fund_return_category_rank_ytd\",\"fund_return_category_rank_1month\",\"fund_return_category_rank_3months\",\"fund_return_category_rank_1year\",\"fund_return_category_rank_3years\",\n",
    "\"fund_return_category_rank_5years\",\"load_adj_return_1year\",\"load_adj_return_3years\",\"load_adj_return_5years\",\"load_adj_return_10years\",\n",
    "\"top10_holdings\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove metrics that we can caluclate ourselves\n",
    "#keep: \"esg_score\",\"environment_score\", \"sustainability_score\", \"sustainability_rank\",   \"social_score\",  \"governance_score\", \n",
    "mutualFunds.drop(columns=[\"esg_peer_count\",\"peer_esg_min\", \"peer_esg_avg\", \"peer_esg_max\",\n",
    "\"peer_environment_min\", \"peer_environment_avg\", \"peer_environment_max\", \n",
    "\"peer_social_min\", \"peer_social_avg\", \"peer_social_max\",\n",
    "\"peer_governance_min\", \"peer_governance_avg\", \"peer_governance_max\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.loc[: , mutualFunds.dtypes== \"object\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with Data cleanup and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average for each column\n",
    "column_means = mutualFunds.mean(skipna=True, numeric_only=True)\n",
    "# Replace NaN values in each column with the respective column average\n",
    "mutualFunds.fillna(column_means, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.dropna(inplace= True)\n",
    "mutualFunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds.loc[:,mutualFunds.dtypes == \"object\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `fund_category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_category_type_count = mutualFunds[\"fund_category\"].value_counts()[mutualFunds[\"fund_category\"].value_counts() > 150]\n",
    "print(100*fund_category_type_count.sum()/len(mutualFunds))\n",
    "print(fund_category_type_count.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in mutualFunds[\"fund_category\"]:\n",
    "    if cat in fund_category_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"fund_category\"] = mutualFunds[\"fund_category\"].replace(cat, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `fund_family_type_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_family_type_count = mutualFunds[\"fund_family\"].value_counts()[mutualFunds[\"fund_family\"].value_counts() > 150]\n",
    "print(100*fund_family_type_count.sum()/len(mutualFunds))\n",
    "print(fund_family_type_count.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in mutualFunds[\"fund_family\"]:\n",
    "    if cat in fund_family_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"fund_family\"] = mutualFunds[\"fund_family\"].replace(cat, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"fund_family\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning `esg_peer_group`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding threshhold to bin esg_peer_group\n",
    "esg_peer_type_count = mutualFunds[\"esg_peer_group\"].value_counts()[mutualFunds[\"esg_peer_group\"].value_counts() > 100]\n",
    "print(100* esg_peer_type_count.sum()/len(mutualFunds))\n",
    "print(esg_peer_type_count.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the bins of esg_peer_group\n",
    "esg_peer_type_count.index.to_list()\n",
    "#replace bins in dataframe for esg_peer_group\n",
    "for esg in mutualFunds[\"esg_peer_group\"]:\n",
    "    if esg in esg_peer_type_count.index.to_list():\n",
    "        next\n",
    "    else:\n",
    "        mutualFunds[\"esg_peer_group\"] = mutualFunds[\"esg_peer_group\"].replace(esg, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds[\"esg_peer_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutualFunds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error, r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path for the SQLite database\n",
    "db_relative_path = \"mutual_funds_data.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database with relative path\n",
    "db_path = os.path.join(os.getcwd(), db_relative_path)\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    # Query data from SQLite database\n",
    "    query = \"SELECT * FROM mutual_funds_data\"\n",
    "    mutualFunds = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Implementation - 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'fund_yield',\n",
    "    'total_net_assets',\n",
    "    'morningstar_overall_rating',\n",
    "    'fund_annual_report_net_expense_ratio',\n",
    "    'fund_sector_technology'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = mutualFunds[feature_columns]\n",
    "y = mutualFunds['year_to_date_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "For the first data implementation, we've selected the following five feature columns:\n",
    "1. 'fund_yield'\n",
    "2. 'total_net_assets'\n",
    "3. 'morningstar_overall_rating'\n",
    "4. 'fund_annual_report_net_expense_ratio'\n",
    "5. 'fund_sector_technology'\n",
    "We used these features to predict the 'year_to_date_return' of mutual funds. After splitting the data into training and testing sets, we trained a RandomForestRegressor model with a random state of 42.\n",
    "\n",
    "The model achieved a Mean Squared Error (MSE) of 0.00240 and a R-squared (R2): 0.634. This means that the model explains approximately 63.4% of the variance in the 'year_to_date_return' target variable, which is a decent performance. With an accuracy of only 63.4%, we decided to explore additional features or transformations of existing features that could better capture the relationship with the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Implementation - Grid search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],       # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10]    # Minimum number of samples required to split a node\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "model = RandomForestRegressor(random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model\n",
    "predictions = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "After conducting a grid search with cross-validation, we found the best hyperparameters for our Random Forest Regressor model. The optimal parameters were determined to be:\n",
    "\n",
    "max_depth: None\n",
    "min_samples_split: 2\n",
    "n_estimators: 150\n",
    "These parameters suggest that allowing the trees to grow without a maximum depth (max_depth set to None), while requiring a minimum of 2 samples to split a node (min_samples_split), and using an ensemble of 150 trees (n_estimators) yielded the best performance.\n",
    "\n",
    "Using these parameters, we evaluated the model on the test set and obtained the following results:\n",
    "Mean Squared Error (MSE): 0.00242\n",
    "R-squared (R2): 0.631\n",
    "These metrics provide insights into the model's performance. The MSE indicates the average squared difference between the predicted and actual values, with lower values indicating better performance. Meanwhile, the R-squared value represents the proportion of variance in the target variable that is predictable from the independent variables. An R-squared value closer to 1 suggests that the model explains a large portion of the variance in the target variable. Overall, the model seems to perform reasonably well, with a relatively low MSE and a moderate R-squared value. However, there is still room for improvement, and further analysis and fine-tuning may be necessary to enhance the model's performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Implementation - Float Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter float columns\n",
    "float_columns = mutualFunds.select_dtypes(include=['float']).columns.tolist()\n",
    "\n",
    "# Create X and y\n",
    "X = mutualFunds[float_columns]\n",
    "y = mutualFunds['year_to_date_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "X.fillna(X.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis \n",
    "\n",
    "The data implementation initially filters out float columns from the mutual funds dataset, and missing values within these columns are imputed with their respective means. While the warning message regarding setting values on a DataFrame slice during preprocessing is noted, it doesn't seem to affect subsequent operations. Following this, the model is trained using a Random Forest Regressor with default parameters. During testing, the model showcases exceptional performance, achieving a remarkably low Mean Squared Error of approximately 2.03e-07 and an impressively high R-squared value of around 0.99997. These metrics indicate an almost perfect fit of the model to the data, suggesting strong predictive capabilities. However, further investigation into the warning message and potentially implementing safer practices for data preprocessing would enhance the robustness of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new column in your test dataset for the predictions\n",
    "X_test['predicted_year_to_date_return'] = predictions\n",
    "\n",
    "# Check the updated test dataset\n",
    "print(X_test.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
